# -*- coding: utf-8 -*-
"""Sentiment Analysis App.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EkfQJaOXcSSVZhBRQFg31YmaFN8BvTTu

install the streamlit
"""

!pip install streamlit

!pip install streamlit pyngrok --quiet

import streamlit as st
import pandas as pd
import re
import nltk
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.ensemble import RandomForestClassifier

nltk.download('stopwords')
stopwords_list = stopwords.words('english')

# Load data
@st.cache_data
def load_data():
    df = pd.read_csv('/content/twitter_training.csv', names=['id', 'Entities', 'Sentiment', 'Text'])
    df.dropna(inplace=True)
    df.drop_duplicates(inplace=True)
    return df

# Preprocessing function
def preprocess_text(text):
    text = text.lower()
    # Wrap the regex operation in a try-except block
    try:
        text = re.sub(r"http\S+", "", text)
        text = re.sub(r"[^a-zA-Z\s]", "", text)
    except KeyboardInterrupt:
        print("Regex operation interrupted. Skipping this row.")
        return ""  # Return an empty string to avoid errors in further processing
    tokens = text.split()
    tokens = [word for word in tokens if word not in stopwords_list]
    return " ".join(tokens)

# Train model
def train_model(df):
    try:
        X = df['Text'].apply(preprocess_text)
        y = df['Sentiment']
        vectorizer = CountVectorizer()
        X_vec = vectorizer.fit_transform(X)
        model = RandomForestClassifier(random_state=42)
        model.fit(X_vec, y)
        return model, vectorizer
    except KeyboardInterrupt:
        print("Model training interrupted.")
        return None, None  # Return None to indicate interruption

# Load and train
# Wrap data loading and model training in a try-except block
try:
    df = load_data()
    model, vectorizer = train_model(df)
except KeyboardInterrupt:
    print("Data loading or model training interrupted.")
    st.error("An error occurred. Please try again.")  # Display error message in Streamlit
    st.stop()  # Stop Streamlit execution to prevent further errors

# ... (rest of your Streamlit code) ...
# Streamlit interface
st.title("📝 Tweet Sentiment Analyzer")

user_input = st.text_area("Enter a tweet to analyze sentiment:", height=150)

if st.button("Analyze Sentiment"):
    if user_input.strip() == "":
        st.warning("Please enter some text.")
    else:
        processed = preprocess_text(user_input)
        vectorized = vectorizer.transform([processed])
        prediction = model.predict(vectorized)[0]

        # Normalize and display nicely
        sentiment_map = {
            'Positive': '🟢 Positive',
            'Negative': '🔴 Negative',
            'Neutral': '🟡 Neutral'
        }

        sentiment_display = sentiment_map.get(prediction, f"🔘 {prediction}")
        st.markdown(f"**Predicted Sentiment:** {sentiment_display}")

from google.colab import files
uploaded = files.upload()

!ngrok authtoken your authtoken

!pkill streamlit
!pkill ngrok

from pyngrok import ngrok
import time
import threading

# Start streamlit in a background thread
def run_streamlit():
    !streamlit run app.py --server.port 8501 > /dev/null 2>&1

# Kill old tunnels
ngrok.kill()

# Start Streamlit
thread = threading.Thread(target=run_streamlit)
thread.start()

# Wait for server to spin up
time.sleep(5)

# Connect to ngrok
public_url = ngrok.connect(8501)
print("✅ Streamlit app is live at:", public_url)

# Streamlit app is live at: "http://localhost:8501/" (This is a comment, not executable code)

